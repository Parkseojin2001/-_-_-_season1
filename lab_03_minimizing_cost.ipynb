{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdDE1LL8saAwFn/R92Pacs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parkseojin2001/DeepLearningZeroToAll/blob/main/lab_03_minimizing_cost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deeper Look at Gradient Descent"
      ],
      "metadata": {
        "id": "eP4NIqYSDTod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "-dz7uCFLDPog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "izmGwy9vCqzq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "metadata": {
        "id": "kC58Eti3Drix"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simpler Hypothesis Function\n",
        "\n",
        "$$H(x) = Wx$$"
      ],
      "metadata": {
        "id": "KlGKVpqEDYhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad = True)\n",
        "hypothesis = W * x_train"
      ],
      "metadata": {
        "id": "M3FUAWGXDRQY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost function : MSE\n",
        "\n",
        "$$cost(W) = \\frac{1}{m} \\sum_{i = 1}^{m}(H(x^{i}) - y^{(i)})^2$$"
      ],
      "metadata": {
        "id": "PuLNRPC5D4DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cost = torch.mean((hypothesis - y_train) ** 2)"
      ],
      "metadata": {
        "id": "thWI3FT-D1my"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "\n",
        "$$cost(W) = \\frac{1}{m} \\sum_{i = 1}^{m}(Wx^{(i)} - y^{(i)})^2$$\n",
        "\n",
        "$$\\nabla W = \\frac {\\partial cost}{\\partial W} = \\frac {2}{m} \\sum_{i = 1}^{m}(Wx^{(i)} - y^{(i)})x^{(i)}$$\n",
        "\n",
        "$$W := W - \\alpha∇W$$"
      ],
      "metadata": {
        "id": "ulVY0yKREjHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradient = 2 * torch.mean((W * x_train - y_train) * x_train)\n",
        "lr = 0.1\n",
        "W = W - lr * gradient"
      ],
      "metadata": {
        "id": "aAUP0P2REMGl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Code"
      ],
      "metadata": {
        "id": "OfXzKOZlJjzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "# initialization\n",
        "W = torch.zeros(1)\n",
        "# learning rate\n",
        "lr = 0.1\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train * W\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  # gradient 계산\n",
        "  gradient = 2 * torch.mean((W * x_train - y_train) * x_train)\n",
        "\n",
        "  print('Epoch {:4d}/{} W: {:.3f}, cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
        "\n",
        "  # cost gradient로 H(x) 개선\n",
        "  W -= lr * gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV30U2CaJYZw",
        "outputId": "246468fb-b28f-42f0-a720-d99ce9c37136"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/10 W: 0.000, cost: 4.666667\n",
            "Epoch    1/10 W: 0.933, cost: 0.020741\n",
            "Epoch    2/10 W: 0.996, cost: 0.000092\n",
            "Epoch    3/10 W: 1.000, cost: 0.000000\n",
            "Epoch    4/10 W: 1.000, cost: 0.000000\n",
            "Epoch    5/10 W: 1.000, cost: 0.000000\n",
            "Epoch    6/10 W: 1.000, cost: 0.000000\n",
            "Epoch    7/10 W: 1.000, cost: 0.000000\n",
            "Epoch    8/10 W: 1.000, cost: 0.000000\n",
            "Epoch    9/10 W: 1.000, cost: 0.000000\n",
            "Epoch   10/10 W: 1.000, cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Code : torch.optim"
      ],
      "metadata": {
        "id": "L3eZYgFLMmgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad = True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W], lr = 0.15)\n",
        "\n",
        "nb_epochs= 15\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train * W\n",
        "\n",
        "  # cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  print('Epoch: {:4d}\\{} W: {:.3f} Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), cost.item()))\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt1-YY01Md8v",
        "outputId": "ed8c6296-9480-47b5-c74e-6b40536fc558"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:    0\\15 W: 0.000 Cost: 4.666667\n",
            "Epoch:    1\\15 W: 1.400 Cost: 0.746667\n",
            "Epoch:    2\\15 W: 0.840 Cost: 0.119467\n",
            "Epoch:    3\\15 W: 1.064 Cost: 0.019115\n",
            "Epoch:    4\\15 W: 0.974 Cost: 0.003058\n",
            "Epoch:    5\\15 W: 1.010 Cost: 0.000489\n",
            "Epoch:    6\\15 W: 0.996 Cost: 0.000078\n",
            "Epoch:    7\\15 W: 1.002 Cost: 0.000013\n",
            "Epoch:    8\\15 W: 0.999 Cost: 0.000002\n",
            "Epoch:    9\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   10\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   11\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   12\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   13\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   14\\15 W: 1.000 Cost: 0.000000\n",
            "Epoch:   15\\15 W: 1.000 Cost: 0.000000\n"
          ]
        }
      ]
    }
  ]
}